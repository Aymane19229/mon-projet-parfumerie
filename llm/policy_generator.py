"""
G√©n√©rateur Principal de Politiques de S√©curit√© avec LLM

Pourquoi : Orchestrer la g√©n√©ration de politiques √† partir des vuln√©rabilit√©s pars√©es
Comment : Charge les vuln√©rabilit√©s, g√©n√®re les prompts, appelle les LLMs, sauvegarde les r√©sultats
"""
import json
import os
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime

from .prompts.nist_csf_prompt import NISTCSFPrompt
from .prompts.iso27001_prompt import ISO27001Prompt

# Import pour la v√©rification de type
try:
    from .models.huggingface import HuggingFaceAPI
except ImportError:
    HuggingFaceAPI = None


class PolicyGenerator:
    """
    G√©n√©rateur principal pour cr√©er des politiques de s√©curit√© avec LLM
    
    Pourquoi : Automatiser la g√©n√©ration de politiques conformes NIST/ISO √† partir des vuln√©rabilit√©s
    Comment : Utilise les prompts structur√©s et les LLMs pour g√©n√©rer les politiques
    """
    
    def __init__(self, vulnerabilities_file: str = "parser/reports/normalized_vulnerabilities.json",
                 llm_provider: str = "deepseek", model_name: Optional[str] = None):
        """
        Initialise le g√©n√©rateur de politiques
        
        Args:
            vulnerabilities_file: Chemin vers le fichier JSON des vuln√©rabilit√©s normalis√©es
            llm_provider: "deepseek" (recommand√©) ou "huggingface"
            model_name: Nom du mod√®le sp√©cifique (optionnel)
                - DeepSeek: "deepseek-chat" (d√©faut) ou "deepseek-reasoner" (R1)
                - HuggingFace: "meta-llama/Meta-Llama-3-8B-Instruct" ou autre mod√®le
        """
        self.vulnerabilities_file = Path(vulnerabilities_file)
        self.llm_provider = llm_provider
        self.model_name = model_name
        self.vulnerabilities: List[Dict] = []
        self.llm = None
        
    def load_vulnerabilities(self) -> List[Dict]:
        """
        Charge les vuln√©rabilit√©s depuis le fichier JSON normalis√©
        
        Pourquoi : Utiliser les vuln√©rabilit√©s pars√©es pour g√©n√©rer les politiques
        Comment : Lit le fichier JSON et retourne la liste des vuln√©rabilit√©s
        
        Returns:
            Liste des vuln√©rabilit√©s normalis√©es
        """
        try:
            if not self.vulnerabilities_file.exists():
                print(f"‚ö†Ô∏è  Fichier non trouv√©: {self.vulnerabilities_file}")
                print("üí° Ex√©cutez d'abord: python parser/main_parser.py")
                return []
            
            with open(self.vulnerabilities_file, 'r', encoding='utf-8') as f:
                self.vulnerabilities = json.load(f)
            
            print(f"‚úÖ {len(self.vulnerabilities)} vuln√©rabilit√©s charg√©es")
            return self.vulnerabilities
            
        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur lors du parsing JSON: {e}")
            return []
        except Exception as e:
            print(f"‚ùå Erreur lors du chargement: {e}")
            return []
    
    def initialize_llm(self):
        """
        Initialise le LLM selon le provider choisi
        
        Pourquoi : Charger le mod√®le LLM pour g√©n√©rer les politiques
        Comment : Importe et initialise le bon wrapper selon le provider
        """
        if self.llm_provider == "deepseek":
            # DeepSeek R1 - Recommand√© : performant et √©conomique
            from .models.deepseek import DeepSeekLLM
            model = self.model_name or "deepseek-chat"
            self.llm = DeepSeekLLM(model=model)
            print(f"‚úÖ LLM initialis√©: DeepSeek {model}")
            
        elif self.llm_provider == "huggingface":
            # Utiliser l'API plut√¥t que le chargement local (plus simple, pas besoin de GPU)
            from .models.huggingface import HuggingFaceAPI
            self.llm = HuggingFaceAPI()
            # Note: le mod√®le sera pass√© lors de l'appel √† generate()
            print(f"‚úÖ LLM initialis√©: Hugging Face API")
            
        elif self.llm_provider == "huggingface-local":
            # Option pour charger le mod√®le localement (n√©cessite GPU)
            from .models.huggingface import HuggingFaceLLM
            model = self.model_name or "meta-llama/Meta-Llama-3-8B-Instruct"
            self.llm = HuggingFaceLLM(model_name=model)
            print(f"‚úÖ LLM initialis√©: Hugging Face Local {model}")
            print("‚ö†Ô∏è  Note: Le chargement local n√©cessite un GPU et beaucoup de RAM")
            
        else:
            raise ValueError(f"Provider LLM inconnu: {self.llm_provider}. Utiliser 'deepseek' (recommand√©) ou 'huggingface'")
    
    def generate_nist_csf_policy(self, framework_category: str = "PROTECT") -> str:
        """
        G√©n√®re une politique NIST CSF
        
        Pourquoi : Cr√©er une politique conforme au NIST Cybersecurity Framework
        Comment : Utilise le prompt NIST et le LLM pour g√©n√©rer la politique
        
        Args:
            framework_category: Cat√©gorie NIST (IDENTIFY, PROTECT, DETECT, RESPOND, RECOVER)
            
        Returns:
            Politique g√©n√©r√©e (texte)
        """
        if not self.vulnerabilities:
            self.load_vulnerabilities()
        
        if not self.llm:
            self.initialize_llm()
        
        print(f"\nüîÑ G√©n√©ration d'une politique NIST CSF ({framework_category})...")
        
        # G√©n√©rer le prompt
        prompt = NISTCSFPrompt.generate_policy_prompt(self.vulnerabilities, framework_category)
        
        # G√©n√©rer la politique avec le LLM
        if isinstance(self.llm, HuggingFaceAPI) and self.model_name:
            # Pour HuggingFaceAPI, passer le mod√®le en param√®tre
            policy = self.llm.generate(prompt, model=self.model_name)
        else:
            policy = self.llm.generate(prompt)
        
        print("‚úÖ Politique NIST CSF g√©n√©r√©e!")
        
        return policy
    
    def generate_iso27001_policy(self, iso_control: str = "A.14.2.5") -> str:
        """
        G√©n√®re une politique ISO 27001
        
        Pourquoi : Cr√©er une politique conforme √† ISO/IEC 27001
        Comment : Utilise le prompt ISO et le LLM pour g√©n√©rer la politique
        
        Args:
            iso_control: Contr√¥le ISO 27001 (ex: A.14.2.5)
            
        Returns:
            Politique g√©n√©r√©e (texte)
        """
        if not self.vulnerabilities:
            self.load_vulnerabilities()
        
        if not self.llm:
            self.initialize_llm()
        
        print(f"\nüîÑ G√©n√©ration d'une politique ISO 27001 ({iso_control})...")
        
        # G√©n√©rer le prompt
        prompt = ISO27001Prompt.generate_policy_prompt(self.vulnerabilities, iso_control)
        
        # G√©n√©rer la politique avec le LLM
        if HuggingFaceAPI and isinstance(self.llm, HuggingFaceAPI) and self.model_name:
            # Pour HuggingFaceAPI, passer le mod√®le en param√®tre
            policy = self.llm.generate(prompt, model=self.model_name)
        else:
            policy = self.llm.generate(prompt)
        
        print("‚úÖ Politique ISO 27001 g√©n√©r√©e!")
        
        return policy
    
    def save_policy(self, policy: str, framework: str, identifier: str, output_dir: Optional[str] = None):
        """
        Sauvegarde une politique g√©n√©r√©e
        
        Pourquoi : Stocker les politiques pour r√©f√©rence et √©valuation
        Comment : Sauvegarde dans un fichier markdown structur√©
        
        Args:
            policy: Texte de la politique
            framework: "nist_csf" ou "iso27001"
            identifier: Identifiant unique (ex: "PROTECT", "A.14.2.5")
            output_dir: Dossier de sortie (optionnel)
        """
        if output_dir is None:
            output_dir = f"llm/policies/{framework}"
        
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # Nom du fichier
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{framework}_{identifier}_{timestamp}.md"
        filepath = output_path / filename
        
        # Ajouter les m√©tadonn√©es
        metadata = f"""---
framework: {framework}
identifier: {identifier}
generated_date: {datetime.now().isoformat()}
vulnerabilities_count: {len(self.vulnerabilities)}
---

"""
        
        # Sauvegarder
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(metadata)
            f.write(policy)
        
        print(f"üíæ Politique sauvegard√©e: {filepath}")
        
        return filepath
    
    def generate_all_policies(self, output_dir: Optional[str] = None):
        """
        G√©n√®re toutes les politiques (NIST CSF et ISO 27001)
        
        Pourquoi : Cr√©er un ensemble complet de politiques
        Comment : G√©n√®re plusieurs politiques pour diff√©rents domaines
        
        Returns:
            Liste des fichiers g√©n√©r√©s
        """
        if not self.vulnerabilities:
            self.load_vulnerabilities()
        
        if not self.llm:
            self.initialize_llm()
        
        generated_files = []
        
        print("\n" + "="*60)
        print("üöÄ G√âN√âRATION DE TOUTES LES POLITIQUES")
        print("="*60)
        
        # NIST CSF - G√©n√©rer pour PROTECT (le plus important)
        print("\nüìã NIST CSF - PROTECT")
        nist_policy = self.generate_nist_csf_policy("PROTECT")
        nist_file = self.save_policy(nist_policy, "nist_csf", "PROTECT", output_dir)
        generated_files.append(nist_file)
        
        # ISO 27001 - G√©n√©rer pour A.14.2.5 (S√©curit√© des applications)
        print("\nüìã ISO 27001 - A.14.2.5")
        iso_policy = self.generate_iso27001_policy("A.14.2.5")
        iso_file = self.save_policy(iso_policy, "iso27001", "A.14.2.5", output_dir)
        generated_files.append(iso_file)
        
        print("\n" + "="*60)
        print(f"‚úÖ {len(generated_files)} politiques g√©n√©r√©es avec succ√®s!")
        print("="*60)
        
        return generated_files


def main():
    """
    Point d'entr√©e principal
    
    Pourquoi : Permettre d'ex√©cuter le g√©n√©rateur depuis la ligne de commande
    Comment : python llm/policy_generator.py
    """
    import sys
    
    # Param√®tres par d√©faut - DeepSeek R1 est maintenant le d√©faut (recommand√©)
    vulnerabilities_file = sys.argv[1] if len(sys.argv) > 1 else "parser/reports/normalized_vulnerabilities.json"
    llm_provider = sys.argv[2] if len(sys.argv) > 2 else "deepseek"
    model_name = sys.argv[3] if len(sys.argv) > 3 else None
    
    # Cr√©er le g√©n√©rateur
    generator = PolicyGenerator(
        vulnerabilities_file=vulnerabilities_file,
        llm_provider=llm_provider,
        model_name=model_name
    )
    
    # G√©n√©rer toutes les politiques
    generator.generate_all_policies()


if __name__ == "__main__":
    main()

