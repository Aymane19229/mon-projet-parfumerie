# üöÄ Guide d'Utilisation : G√©n√©rateur de Politiques avec LLM

## üéØ Objectif

G√©n√©rer automatiquement des **politiques de s√©curit√© conformes** (NIST CSF, ISO 27001) √† partir des vuln√©rabilit√©s d√©tect√©es par le pipeline DevSecOps.

---

## üìã Pr√©requis

### 1. Installer les D√©pendances

```bash
cd mon-projet-parfumerie
pip install -r llm/requirements.txt
```

### 2. Configurer les Cl√©s API

**Option A : DeepSeek R1 - ‚≠ê RECOMMAND√â (Par d√©faut)**

1. Cr√©er un compte sur https://platform.deepseek.com
2. G√©n√©rer une cl√© API (gratuite au d√©marrage)
3. Cr√©er un fichier `.env` dans le dossier `llm/` :
   ```
   DEEPSEEK_API_KEY=sk-votre_cle_api_ici
   ```
   **Avantages :** Performant, √©conomique, open-source !

**Option B : Hugging Face (LLaMA 3) - Gratuit**

1. Cr√©er un compte sur https://huggingface.co
2. Accepter les termes pour LLaMA 3
3. Optionnel : G√©n√©rer une cl√© API pour les mod√®les priv√©s
4. Cr√©er un fichier `.env` :
   ```
   HUGGINGFACE_API_KEY=votre_cle_ici  # Optionnel
   ```

---

## üîÑ Workflow Complet

```
1. Pipeline DevSecOps d√©tecte des vuln√©rabilit√©s
         ‚Üì
2. Parser normalise les rapports ‚Üí normalized_vulnerabilities.json
         ‚Üì
3. LLM g√©n√®re des politiques conformes
         ‚Üì
4. Politiques sauvegard√©es dans llm/policies/
```

---

## üöÄ Utilisation

### M√©thode 1 : Ligne de Commande

```bash
# Avec DeepSeek R1 (d√©faut - recommand√©)
python llm/policy_generator.py

# Avec DeepSeek R1 Reasoner (raisonnement avanc√©)
python llm/policy_generator.py parser/reports/normalized_vulnerabilities.json deepseek deepseek-reasoner

# Avec Hugging Face (LLaMA 3)
python llm/policy_generator.py parser/reports/normalized_vulnerabilities.json huggingface
```

### M√©thode 2 : Depuis Python

```python
from llm.policy_generator import PolicyGenerator

# Cr√©er le g√©n√©rateur avec DeepSeek R1 (d√©faut - recommand√©)
generator = PolicyGenerator(
    vulnerabilities_file="parser/reports/normalized_vulnerabilities.json",
    llm_provider="deepseek",  # ou "huggingface"
    model_name="deepseek-chat"  # ou "deepseek-reasoner" pour R1
)

# OU simplement (DeepSeek est le d√©faut maintenant)
generator = PolicyGenerator()
```

# G√©n√©rer une politique NIST CSF
nist_policy = generator.generate_nist_csf_policy("PROTECT")
generator.save_policy(nist_policy, "nist_csf", "PROTECT")

# G√©n√©rer une politique ISO 27001
iso_policy = generator.generate_iso27001_policy("A.14.2.5")
generator.save_policy(iso_policy, "iso27001", "A.14.2.5")

# OU g√©n√©rer toutes les politiques
generator.generate_all_policies()
```

---

## üìä R√©sultats

Les politiques sont sauvegard√©es dans :
- `llm/policies/nist_csf/` - Politiques NIST CSF
- `llm/policies/iso27001/` - Politiques ISO 27001

Format des fichiers :
- Nom : `{framework}_{identifier}_{timestamp}.md`
- Contenu : Politique compl√®te en Markdown avec m√©tadonn√©es

---

## üîß Configuration Avanc√©e

### Personnaliser les Prompts

Modifier les fichiers :
- `llm/prompts/nist_csf_prompt.py` - Pour NIST CSF
- `llm/prompts/iso27001_prompt.py` - Pour ISO 27001

### Choisir le Mod√®le LLM

**DeepSeek R1 (Recommand√©) :**
- `deepseek-chat` : Mod√®le conversationnel standard (0.55$/1M tokens)
- `deepseek-reasoner` : R1 avec raisonnement avanc√© (meilleure qualit√©)

**Hugging Face :**
- `meta-llama/Meta-Llama-3-8B-Instruct` : LLaMA 3 (gratuit via API)
- `mistralai/Mistral-7B-Instruct-v0.2` : Mistral (gratuit via API)
- Autres mod√®les disponibles sur Hugging Face

---

## üìù Exemple de Politique G√©n√©r√©e

Chaque politique contient :
1. **M√©tadonn√©es** (YAML frontmatter)
2. **Informations de base** (ID, titre, r√©f√©rences)
3. **Objectif et port√©e**
4. **Exigences d√©taill√©es** bas√©es sur les vuln√©rabilit√©s
5. **Mesures de contr√¥le** actionnables
6. **Responsabilit√©s**
7. **Conformit√© et audit**

---

## ‚ö†Ô∏è Notes Importantes

1. **Co√ªts** : 
   - DeepSeek : Tr√®s √©conomique (0.55$/1M tokens) - **Recommand√©**
   - Hugging Face : Gratuit (selon le mod√®le)
   - V√©rifiez vos limites d'utilisation
2. **R√©sultats** : Les politiques g√©n√©r√©es doivent √™tre revues et adapt√©es.
3. **Conformit√©** : V√©rifiez que les politiques respectent bien NIST/ISO.
4. **Performance** : Les LLMs peuvent prendre du temps (30 secondes √† plusieurs minutes).
   - DeepSeek reasoner peut prendre plus de temps (raisonnement approfondi)

---

## üîç D√©pannage

### Erreur : "DEEPSEEK_API_KEY non configur√©e"
- V√©rifiez que le fichier `.env` existe dans `llm/`
- OU d√©finissez la variable d'environnement : `export DEEPSEEK_API_KEY=votre_cle`
- Cr√©ez un compte sur https://platform.deepseek.com

### Erreur : "HUGGINGFACE_API_KEY non configur√©e" (pour certains mod√®les)
- Certains mod√®les Hugging Face n√©cessitent une cl√© API
- Cr√©ez un compte sur https://huggingface.co
- OU utilisez un mod√®le public qui ne n√©cessite pas de cl√©

### Erreur : "Fichier vuln√©rabilit√©s non trouv√©"
- Ex√©cutez d'abord : `python parser/main_parser.py`

### Erreur : "Module non trouv√©"
- Installez les d√©pendances : `pip install -r llm/requirements.txt`

---

## ‚úÖ Prochaines √âtapes

Apr√®s avoir g√©n√©r√© les politiques :

1. **√âvaluer la qualit√©** avec BLEU/ROUGE-L (module √† venir)
2. **Comparer avec des r√©f√©rences** NIST/ISO
3. **R√©viser et adapter** les politiques g√©n√©r√©es
4. **Documenter** dans le rapport final

---

## üìö Ressources

- [NIST Cybersecurity Framework](https://www.nist.gov/cyberframework)
- [ISO/IEC 27001](https://www.iso.org/isoiec-27001-information-security.html)
- [OpenAI API Documentation](https://platform.openai.com/docs)
- [Hugging Face Models](https://huggingface.co/models)

